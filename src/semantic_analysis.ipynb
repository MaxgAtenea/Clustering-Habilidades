{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae484fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb402a2d-323e-448d-ae46-fe8209861776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ecaac66-262a-458c-9ac7-cabe27c19480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxal\\venvs\\global_venv\\my_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15bdbc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "     ------------------------------------ 345.7/345.7 kB 613.3 kB/s eta 0:00:00\n",
      "Collecting plotly\n",
      "  Downloading plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
      "     -------------------------------------- 14.8/14.8 MB 609.5 kB/s eta 0:00:00\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Collecting huggingface-hub>=0.20.0\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "     -------------------------------------- 481.4/481.4 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: Pillow in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from sentence-transformers) (9.3.0)\n",
      "Collecting typing_extensions>=4.5.0\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "     -------------------------------------- 45.8/45.8 kB 564.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from sentence-transformers) (1.6.2)\n",
      "Collecting torch>=1.11.0\n",
      "  Downloading torch-2.7.0-cp39-cp39-win_amd64.whl (212.4 MB)\n",
      "     ------------------------------------ 212.4/212.4 MB 198.6 kB/s eta 0:00:00\n",
      "Collecting transformers<5.0.0,>=4.41.0\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "     ---------------------------------------- 10.4/10.4 MB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp39-cp39-win_amd64.whl (11.2 MB)\n",
      "     -------------------------------------- 11.2/11.2 MB 506.8 kB/s eta 0:00:00\n",
      "Collecting narwhals>=1.15.1\n",
      "  Downloading narwhals-1.36.0-py3-none-any.whl (331 kB)\n",
      "     ------------------------------------ 331.0/331.0 kB 526.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from plotly) (21.3)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "     ------------------------------------ 194.4/194.4 kB 491.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from packaging->plotly) (3.0.9)\n",
      "Requirement already satisfied: networkx in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2.8.4)\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "     ---------------------------------------- 6.2/6.2 MB 553.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.20.1)\n",
      "Collecting safetensors>=0.4.3\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "     ------------------------------------ 308.9/308.9 kB 502.8 kB/s eta 0:00:00\n",
      "Collecting tokenizers<0.22,>=0.21\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 708.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.7.9)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "     ------------------------------------ 301.8/301.8 kB 454.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maxal\\appdata\\local\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Installing collected packages: typing_extensions, threadpoolctl, sympy, safetensors, python-dotenv, narwhals, joblib, fsspec, filelock, torch, scikit-learn, plotly, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.9\n",
      "    Uninstalling sympy-1.9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'c:\\\\users\\\\maxal\\\\appdata\\\\local\\\\arcgis\\\\pro\\\\bin\\\\python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\sympy-1.9-py3.9.egg'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers plotly python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b251f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "191c30b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.16 [MSC v.1931 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a637bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxal\\AppData\\Local\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50ba5e4",
   "metadata": {},
   "source": [
    "## Variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9831759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Leer la API Key\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a890b4",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9808f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_parse_conocimientos(value):\n",
    "    '''\n",
    "    Cambia de formato las entradas de la forma\n",
    "    \"'palabra_1','palabra_2',..., 'palabra_n'\"\n",
    "    a\n",
    "    ['palabra_1','palabra_2,...,'palabra_n']\n",
    "    '''\n",
    "    try:\n",
    "        # Si no está entre corchetes, lo envolvemos\n",
    "        if not value.strip().startswith(\"[\"):\n",
    "            value = f\"[{value}]\"\n",
    "        return ast.literal_eval(value)\n",
    "    except Exception:\n",
    "        return [str(value)]  # Si no se puede evaluar, lo devolvemos como lista con un solo string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7ad885",
   "metadata": {},
   "source": [
    "## Lectura datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58d11811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3087, 26)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conoc_df=pd.read_excel(\"../data/conoc_tej.xlsx\",index_col=False).copy()\n",
    "conoc_df=conoc_df.replace('NA',np.nan)\n",
    "conoc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa7602a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'mantenimiento de maquinaria industrial', 'manejo de bombas de vacío', 'equipos de soldadura', 'mecánica hidráulica'\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conocimientos de la vacante\n",
    "conoc_df['conocimientos'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1cf4a",
   "metadata": {},
   "source": [
    "## Clusterizarion semántica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53893030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Define the corpus\n",
    "corpus = conoc_df['conocimientos'].apply(safe_parse_conocimientos).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7348640f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16508, 384)\n"
     ]
    }
   ],
   "source": [
    "# 2. Embed skills\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "skill_embeddings = model.encode(corpus)\n",
    "\n",
    "print(skill_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4958ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Compute hierarchical clustering\n",
    "linked = linkage(skill_embeddings, method='ward')  # \"ward\" tries to minimize variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7be811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "# 4. Create Plotly Dendrogram\n",
    "fig = ff.create_dendrogram(skill_embeddings, labels=corpus, linkagefun=lambda x: linkage(x, 'ward'))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    title=\"Dynamic Skill Clustering Dendrogram\",\n",
    "    xaxis_title=\"Skills\",\n",
    "    yaxis_title=\"Distance\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.write_html(\"../output/skill_dendogram.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f706f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Optional: Cut the dendrogram into \"k\" clusters\n",
    "num_clusters = 10\n",
    "cluster_labels = fcluster(linked, num_clusters, criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71b75177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skill: mantenimiento de maquinaria industrial, Cluster: 7\n",
      "Skill: manejo de bombas de vacío, Cluster: 7\n",
      "Skill: equipos de soldadura, Cluster: 7\n",
      "Skill: mecánica hidráulica, Cluster: 7\n",
      "Skill: Control integrado de plagas, Cluster: 6\n",
      "Skill: Control de roedores, Cluster: 6\n",
      "Skill: Desinsectación, Cluster: 7\n",
      "Skill: Lavado y desinfección de tanques, Cluster: 7\n",
      "Skill: Curso de trabajo en alturas, Cluster: 5\n",
      "Skill: Licencias A2 y C1, Cluster: 7\n"
     ]
    }
   ],
   "source": [
    "# 6. Print results\n",
    "n=1\n",
    "for skill, cluster_id in zip(corpus, cluster_labels):\n",
    "    if n<=10:\n",
    "        print(f\"Skill: {skill}, Cluster: {cluster_id}\")\n",
    "        n+=1\n",
    "    else: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58f1db6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 7: ['mantenimiento de maquinaria industrial', 'manejo de bombas de vacío', 'equipos de soldadura', 'mecánica hidráulica', 'Desinsectación', 'Lavado y desinfección de tanques', 'Licencias A2 y C1', 'Inglés', 'Gestora y consultora asesora', 'NO_APLICA', 'Mercado de energía colombiano', 'Cobro de cartera', 'Manejo de tecnicos', 'Medida directa y semidirecta', 'Construcción', 'Manejo de correspondencia', 'Regulaciones gubernamentales', 'Herramienta SAP', 'Planeación de compras y contratación', 'Herramienta SAP', 'NO_APLICA', 'NO_APLICA', 'Equipos de calentamiento', 'Sistema de aire a presión', 'Consumo de agua', 'Huella de carbono', 'Mejora continua', 'Limpieza y lubricación de máquinas y equipos', 'Mantenimientos preventivos de maquinaria', 'Lavados de techos de casetas']\n"
     ]
    }
   ],
   "source": [
    "#7. Label the clusters using an LLM:\n",
    "\n",
    "# For each cluster, summarize its skills\n",
    "from collections import defaultdict\n",
    "\n",
    "cluster_skills = defaultdict(list)\n",
    "for skill, cluster_id in zip(corpus, cluster_labels):\n",
    "    cluster_skills[cluster_id].append(skill)\n",
    "\n",
    "for cluster_id, cluster_list in cluster_skills.items():\n",
    "    #truncar el print\n",
    "    print(f\"Cluster {cluster_id}: {cluster_list[0:30]}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9fd730",
   "metadata": {},
   "source": [
    "## Etiquetar el cluster con un LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3856e06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basado en el listado de habilidades y conocimientos laborales, te sugiero los siguientes nombres que resumen las habilidades:\n",
      "\n",
      "1. \"Electromecánico Especializado\"\n",
      "2. \"Técnico en Redes Eléctricas\"\n",
      "3. \"Especialista en Instalaciones Eléctricas\"\n",
      "4. \"Mantenimiento y Reparación Eléctrica\"\n",
      "5. \"Diseñador de Sistemas Eléctricos\"\n",
      "6. \"Técnico en Electricidad Industrial\"\n",
      "7. \"Especialista en Motores Eléctricos\"\n",
      "8. \"Instalador y Mantenedor de Redes Eléctricas\"\n",
      "9. \"Técnico en Cableado Estructurado\"\n",
      "10. \"Especialista en Energía Eléctrica\"\n",
      "\n",
      "Espero que alguno de estos nombres te sea útil. Recuerda que es importante adaptar el nombre a la industria o sector en el que te desenvuelvas.\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "#E.g Primer cluster\n",
    "skills_list = cluster_skills[2][:500]\n",
    "\n",
    "# Spanish prompt\n",
    "prompt = f\"Dado el siguiente listado de habilidades/conocimientos laborales: {', '.join(skills_list)}, sugiere un nombre de max 10 palabras que resuma las habilidades\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"llama3-8b-8192\",  # Or \"llama3-70b-8192\"\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    \"temperature\": 0.3\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.groq.com/openai/v1/chat/completions\", json=payload, headers=headers)\n",
    "\n",
    "# Verificamos si todo salió bien\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(data[\"choices\"][0][\"message\"][\"content\"])\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f035139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (my_env)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
